{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series ()\n",
    "Section6 - L26 \n",
    "> Series syntax -pd.Series(data, index=[]) > Series operations > Series with different data types > Series indexing > Series , arrays/list difference - Series can handle multiple data type \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "lists = ['a','b','c']\n",
    "data = [10,20,30]\n",
    "array_data = np.array(data)\n",
    "dicts= {'a':1,'b':2, 'c':3}\n",
    "indexed = [1,2,3]\n",
    "\n",
    "series_lists = pd.Series(lists)\n",
    "print('Series list - default indexing\\n',series_lists)\n",
    "series_lists = pd.Series(data=lists, index=['a1','b1','c1'])\n",
    "print('Series list - custom indexing\\n', series_lists)\n",
    "series_lists = pd.Series(lists, indexed)\n",
    "print('Series list - indexed\\n',series_lists)\n",
    "series_array = pd.Series(array_data)\n",
    "print('Array', array_data)    # [10,20,30]\n",
    "print('Series array', series_array) # comes with index default \n",
    "\n",
    "series_dict = pd.Series(dicts)\n",
    "print('Dict series', series_dict)  # key comes as the index values \n",
    "\n",
    "\n",
    "series_ops1 = pd.Series([1,2,3,4], ['US','UK','DE','JA'])\n",
    "series_ops2 = pd.Series([1,2,3,4], ['US','UK','IT', 'FR'])\n",
    "\n",
    "series_ops = series_ops1 + series_ops2\n",
    "print(series_ops)\n",
    "\n",
    "\n",
    "# Series indexing \n",
    "print(series_ops1['UK'])   # use the index to get the values \n",
    "series_check = pd.Series()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames1 \n",
    "Section6 - L27 \n",
    "> DataFrame - syntax pd.DataFrame(data, index, col) > type() keyword > Multiple Series data results in the DataFrame \n",
    "> drop() keyword> inplace arg  > create new col on ops on existing cols \n",
    ">axis =0 row axis =1 columns > selecting rows - loc(labelbased), iloc keyword(integerbased) \n",
    "> selecting columns \n",
    ">.loc keyword for subsetting DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "printing the column W\n",
      "A    2.706850\n",
      "B    0.651118\n",
      "C   -2.018168\n",
      "D    0.188695\n",
      "E    0.190794\n",
      "Name: W, dtype: float64\n",
      "printing 2 columns X, Y\n",
      "          X         Y\n",
      "A  0.628133  0.907969\n",
      "B -0.319318 -0.848077\n",
      "C  0.740122  0.528813\n",
      "D -0.758872 -0.933237\n",
      "E  1.978757  2.605967\n",
      "          W         X         Y         Z       Y+Z\n",
      "A  2.706850  0.628133  0.907969  0.503826  1.411795\n",
      "B  0.651118 -0.319318 -0.848077  0.605965 -0.242112\n",
      "C -2.018168  0.740122  0.528813 -0.589001 -0.060187\n",
      "D  0.188695 -0.758872 -0.933237  0.955057  0.021819\n",
      "E  0.190794  1.978757  2.605967  0.683509  3.289476\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "          W         X         Y         Z       Y+Z\n",
      "B  0.651118 -0.319318 -0.848077  0.605965 -0.242112\n",
      "C -2.018168  0.740122  0.528813 -0.589001 -0.060187\n",
      "D  0.188695 -0.758872 -0.933237  0.955057  0.021819\n",
      "E  0.190794  1.978757  2.605967  0.683509  3.289476\n",
      "          W         X         Y         Z       Y+Z\n",
      "A  2.706850  0.628133  0.907969  0.503826  1.411795\n",
      "B  0.651118 -0.319318 -0.848077  0.605965 -0.242112\n",
      "C -2.018168  0.740122  0.528813 -0.589001 -0.060187\n",
      "D  0.188695 -0.758872 -0.933237  0.955057  0.021819\n",
      "E  0.190794  1.978757  2.605967  0.683509  3.289476\n",
      "Drop after inplace keyword\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "W    2.706850\n",
      "X    0.628133\n",
      "Y    0.907969\n",
      "Z    0.503826\n",
      "Name: A, dtype: float64\n",
      "          W         X         Y         Z\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "W    2.706850\n",
      "X    0.628133\n",
      "Y    0.907969\n",
      "Z    0.503826\n",
      "Name: A, dtype: float64\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "          X         Y\n",
      "A  0.628133  0.907969\n",
      "B -0.319318 -0.848077\n",
      "C  0.740122  0.528813\n",
      "D -0.758872 -0.933237\n",
      "E  1.978757  2.605967\n",
      "0.6281327087844596\n",
      "          X         Y\n",
      "A  0.628133  0.907969\n",
      "B -0.319318 -0.848077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from numpy.random import randn    # to initialise data values for the dataframe \n",
    "\n",
    "np.random.seed(101)\n",
    "df = pd.DataFrame(randn(5,4),['A','B','C','D','E'], ['W','X','Y','Z'])\n",
    "print('DataFrame')\n",
    "print(df)\n",
    "\n",
    "print('printing the column W')\n",
    "print(df['W'])\n",
    "\n",
    "type(df)   # data frame \n",
    "type(df['X']) # Series \n",
    "\n",
    "\n",
    "print('printing 2 columns X, Y')\n",
    "print(df[['X','Y']])\n",
    "type(df[['X','Y']])\n",
    "\n",
    "# creating a new column in dataframe \n",
    "df['Y+Z'] = df['Y'] + df['Z']\n",
    "print(df)\n",
    "\n",
    "# dropping the column - use the axis to mention whether row or column is dropped \n",
    "print(df.drop('Y+Z', axis=1))  # column drop \n",
    "print(df.drop('A', axis=0)) # row drop \n",
    "print(df)\n",
    "\n",
    "# dropping the row, column - Inplace keyword to reflect the change in place \n",
    "# lets drop Y +Z in place \n",
    "df.drop('Y+Z', axis =1 , inplace= True )\n",
    "print('Drop after inplace keyword')\n",
    "print(df)\n",
    "\n",
    "\n",
    "# keyword loc - label based  , iloc - integer based \n",
    "# loc, iloc for displaying rows, columns  \n",
    "print(df.loc['A'])  # displays the A row \n",
    "\n",
    "print(df.loc[['B','C']]) # displays the B , C row \n",
    "\n",
    "print(df.iloc[0])  # displays A row \n",
    "\n",
    "print(df.iloc[[0,1]])   # displays A, B row \n",
    "\n",
    "#  for columns just use []\n",
    "print(df[['X','Y']]) # displays X, Y column \n",
    "\n",
    "# subsetting a dataframe \n",
    "print(df.loc['A','X'])\n",
    "print(df.loc[['A','B'],['X','Y']])  # 0.628133 0.907969\n",
    "                                    # -0.31931 -0.848077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames2 \n",
    "Section 6 - L28 \n",
    "> conditional selection dataframe > 0 => true or false  \n",
    "> Subsetting dataframes in multiple/single step > & , | operators > returning values from boolean conditioning for rows \n",
    "> reset_index- inplace needed > \n",
    "> set_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe df\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "-------------------------------------------------\n",
      "Dataframe df df>0        W      X      Y      Z\n",
      "A   True   True   True   True\n",
      "B   True  False  False   True\n",
      "C  False   True   True  False\n",
      "D   True  False  False   True\n",
      "E   True   True   True   True\n",
      "-------------------------------------------------\n",
      "bool condition W>0\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "-------------------------------------------------\n",
      "bool condition X,Y > 0\n",
      "    W         X         Y   Z\n",
      "A NaN  0.628133  0.907969 NaN\n",
      "B NaN       NaN       NaN NaN\n",
      "C NaN  0.740122  0.528813 NaN\n",
      "D NaN       NaN       NaN NaN\n",
      "E NaN  1.978757  2.605967 NaN\n",
      "-------------------------------------------------\n",
      "Access A row\n",
      "W    2.706850\n",
      "X    0.628133\n",
      "Y    0.907969\n",
      "Z    0.503826\n",
      "Name: A, dtype: float64\n",
      "-------------------------------------------------\n",
      "Access A, B row\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "-------------------------------------------------\n",
      "Access B row > 0\n",
      "W    0.651118\n",
      "Z    0.605965\n",
      "Name: B, dtype: float64\n",
      "Access A, B row > 0\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118       NaN       NaN  0.605965\n",
      "-------------------------------------------------\n",
      "& op X & Y col >0\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "C -2.018168  0.740122  0.528813 -0.589001\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "-------------------------------------------------\n",
      "| op W |Y >0\n",
      "          W         X         Y         Z\n",
      "A  2.706850  0.628133  0.907969  0.503826\n",
      "B  0.651118 -0.319318 -0.848077  0.605965\n",
      "D  0.188695 -0.758872 -0.933237  0.955057\n",
      "E  0.190794  1.978757  2.605967  0.683509\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# boolean conditioning \n",
    "print('Dataframe df')\n",
    "print(df) # the created dataframe \n",
    "print('-------------------------------------------------')\n",
    "\n",
    "print('Dataframe df df>0', df>0) # conditional boolean \n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# accessing columns with boolean condition \n",
    "print('bool condition W>0')\n",
    "bool_df1 = df['W']>0  # check the column W for elements > 0 \n",
    "print(df[bool_df1])\n",
    "print('-------------------------------------------------')\n",
    "\n",
    " # check columns X, Y for elements > 0\n",
    "print('bool condition X,Y > 0')\n",
    "print(df[df[['X', 'Y']]>0])\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# accessing rows with boolean conditioning \n",
    "print('Access A row')\n",
    "print(df.loc['A']) # accessing A row \n",
    "print('-------------------------------------------------')\n",
    "\n",
    "print('Access A, B row')\n",
    "print(df.loc[['A', 'B']]) # accessing A and B row \n",
    "print('-------------------------------------------------')\n",
    "\n",
    "print('Access B row > 0')\n",
    "bool_df2 = df.loc['A']>0 # check A row > than 0 \n",
    "print(df.loc['B'][df.loc['B']>0]) # accessing B row with elements > 0\n",
    "\n",
    "# checking 2 rows with elements > 0 \n",
    "print('Access A, B row > 0')\n",
    "print(df.loc[['A','B']][df.loc[['A', 'B']]>0])\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# Operators & , |\n",
    "print('& op X & Y col >0')\n",
    "bool_df3 = (df['X'] > 0) & (df['Y'] > 0) \n",
    "print(df[bool_df3])\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "print('| op W |Y >0')\n",
    "bool_df4 = (df['W'] >0 ) | (df['Z'] > 0)\n",
    "print(df[bool_df4])\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# Dataframe accessing an element \n",
    "df.loc['A','W']   # 2.706850\n",
    "df.loc[['A','B'],['X','Y']] \n",
    "# \t   X\t           Y\n",
    "# A\t  0.628133\t       0.907969\n",
    "# B\t- 0.319318\t-      0.848077\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               W         X         Y         Z\n",
      "States                                        \n",
      "CA      2.706850  0.628133  0.907969  0.503826\n",
      "OR      0.651118 -0.319318 -0.848077  0.605965\n",
      "NY     -2.018168  0.740122  0.528813 -0.589001\n",
      "MI      0.188695 -0.758872 -0.933237  0.955057\n",
      "II      0.190794  1.978757  2.605967  0.683509\n",
      "-------------------------------------------------\n",
      "          W         X         Y         Z States\n",
      "A  2.706850  0.628133  0.907969  0.503826     CA\n",
      "B  0.651118 -0.319318 -0.848077  0.605965     OR\n",
      "C -2.018168  0.740122  0.528813 -0.589001     NY\n",
      "D  0.188695 -0.758872 -0.933237  0.955057     MI\n",
      "E  0.190794  1.978757  2.605967  0.683509     II\n",
      "--------------------------------------------------\n",
      "  index         W         X         Y         Z States\n",
      "0     A  2.706850  0.628133  0.907969  0.503826     CA\n",
      "1     B  0.651118 -0.319318 -0.848077  0.605965     OR\n",
      "2     C -2.018168  0.740122  0.528813 -0.589001     NY\n",
      "3     D  0.188695 -0.758872 -0.933237  0.955057     MI\n",
      "4     E  0.190794  1.978757  2.605967  0.683509     II\n"
     ]
    }
   ],
   "source": [
    "# reset_index, set_index - inplace needs to be set true \n",
    "# set_index , reset_index keywords \n",
    "stateindex = 'CA OR NY MI II'.split()\n",
    "df['States'] = stateindex\n",
    "print(df.set_index('States'))\n",
    "print('-------------------------------------------------')\n",
    "print(df)\n",
    "print('--------------------------------------------------')\n",
    "print(df.reset_index())  # replaces the old index column and creates new column for the old index \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames 3 \n",
    "Section 6 - L29\n",
    "> Multi index > index.names keyword > indexing a multi level dataframe > cross section xs - level > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex(levels=[['G1', 'G2'], [1, 2, 3]],\n",
      "           codes=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]])\n",
      "--------------------------------------------------\n",
      "             A         B\n",
      "G1 1  0.302665  1.693723\n",
      "   2 -1.706086 -1.159119\n",
      "   3 -0.134841  0.390528\n",
      "G2 1  0.166905  0.184502\n",
      "   2  0.807706  0.072960\n",
      "   3  0.638787  0.329646\n",
      "--------------------------------------------------\n",
      "0.3026654485851825\n",
      "                   A         B\n",
      "Groups Num                    \n",
      "G1     1    0.302665  1.693723\n",
      "       2   -1.706086 -1.159119\n",
      "       3   -0.134841  0.390528\n",
      "G2     1    0.166905  0.184502\n",
      "       2    0.807706  0.072960\n",
      "       3    0.638787  0.329646\n",
      "--------------------------------------------------\n",
      "            A         B\n",
      "Num                    \n",
      "1    0.302665  1.693723\n",
      "2   -1.706086 -1.159119\n",
      "3   -0.134841  0.390528\n",
      "--------------------------------------------------\n",
      "               A         B\n",
      "Groups                    \n",
      "G1      0.302665  1.693723\n",
      "G2      0.166905  0.184502\n"
     ]
    }
   ],
   "source": [
    "# Index Levels\n",
    "outside = ['G1','G1','G1','G2','G2','G2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))  # results in a tuple between inside and outside \n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index) # inbuilt \n",
    "print(hier_index)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# assingning the dataframe \n",
    "df_multi = pd.DataFrame(randn(6,2), hier_index, columns=['A','B'])\n",
    "print(df_multi)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# accessing elements \n",
    "print(df_multi.loc['G1'].loc[1]['A'])   # 0.30266\n",
    "\n",
    "# index.names keywords\n",
    "df_multi.index.names = ['Groups','Num']\n",
    "print(df_multi)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# cross section - with level\n",
    "# xs keyword, level \n",
    "print(df_multi.xs('G1'))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print(df_multi.xs(1, level='Num'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data \n",
    "Section 6 - L30\n",
    "> dropna keyword , thresh, axis \n",
    "> fillna keyword \n",
    "\n",
    "# Groupby \n",
    "Section 6 - L31\n",
    ">groupby keyword > aggregate functions > describe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Dataframe\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  NaN  2\n",
      "2  NaN  NaN  3\n",
      "--------------------------------------------------\n",
      "Drop nan rows\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "--------------------------------------------------\n",
      "Drop nan columns\n",
      "    C\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "--------------------------------------------------\n",
      "Thresh rows\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  NaN  2\n",
      "--------------------------------------------------\n",
      "Thresh columns\n",
      "      A  C\n",
      "0  1.0  1\n",
      "1  2.0  2\n",
      "2  NaN  3\n",
      "Fill nan values\n",
      "       A     B  C\n",
      "0     1     5  1\n",
      "1     2  fill  2\n",
      "2  fill  fill  3\n",
      "Fill nan with mean col values\n",
      "      A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  5.0  2\n",
      "2  1.5  5.0  3\n",
      "--------------------------------------------------\n",
      "Dataframe\n",
      "   Company   Person  Sales\n",
      "0    GOOG      Sam    200\n",
      "1    GOOG  Charlie    120\n",
      "2    MSFT      Amy    340\n",
      "3    MSFT  Vanessa    124\n",
      "4      FB     Carl    243\n",
      "5      FB    Sarah    350\n",
      "Groupby company and sum their sales\n",
      "         Sales\n",
      "Company       \n",
      "FB         593\n",
      "GOOG       320\n",
      "MSFT       464\n",
      "Groupby company and max sales of the company\n",
      "          Person  Sales\n",
      "Company                \n",
      "FB         Sarah    350\n",
      "GOOG         Sam    200\n",
      "MSFT     Vanessa    340\n",
      "--------------------------------------------------\n",
      "Describe groupby\n",
      "         Sales                                                        \n",
      "        count   mean         std    min     25%    50%     75%    max\n",
      "Company                                                              \n",
      "FB        2.0  296.5   75.660426  243.0  269.75  296.5  323.25  350.0\n",
      "GOOG      2.0  160.0   56.568542  120.0  140.00  160.0  180.00  200.0\n",
      "MSFT      2.0  232.0  152.735065  124.0  178.00  232.0  286.00  340.0\n",
      "--------------------------------------------------\n",
      "Transposed Describe groupby\n",
      " Company              FB        GOOG        MSFT\n",
      "Sales count    2.000000    2.000000    2.000000\n",
      "      mean   296.500000  160.000000  232.000000\n",
      "      std     75.660426   56.568542  152.735065\n",
      "      min    243.000000  120.000000  124.000000\n",
      "      25%    269.750000  140.000000  178.000000\n",
      "      50%    296.500000  160.000000  232.000000\n",
      "      75%    323.250000  180.000000  286.000000\n",
      "      max    350.000000  200.000000  340.000000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%config IPCompleter.greedy=True\n",
    "dict_nan = {'A':[1,2,np.nan], 'B':[5,np.nan, np.nan], 'C':[1,2,3]}\n",
    "dict_nan['A']\n",
    "dictnan_df = pd.DataFrame(dict_nan)\n",
    "print('Dictionary Dataframe\\n', dictnan_df)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# drop nan rows  \n",
    "print('Drop nan rows\\n',dictnan_df.dropna())  # axis =0 default - rows \n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# dropna deep \n",
    "print('Drop nan columns\\n',dictnan_df.dropna(axis=1))  # axis =1 columns\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# dropna thresh\n",
    "# threshold for the number of not nan values \n",
    "print('Thresh rows\\n',dictnan_df.dropna(thresh=2))  # drops rows with < 2 not nan values \n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# dropna thresh columns \n",
    "print('Thresh columns\\n', dictnan_df.dropna(axis=1, thresh=2))\n",
    "\n",
    "# fillna keyword \n",
    "print('Fill nan values\\n', dictnan_df.fillna(value = 'fill'))\n",
    "print('Fill nan with mean col values\\n',dictnan_df.fillna(value=dictnan_df[['A','B']].mean()))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# Groupby \n",
    "\n",
    "data_groupie = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "                'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "                'Sales':[200,120,340,124,243,350]}\n",
    "dataframe_groupie = pd.DataFrame(data_groupie)\n",
    "print('Dataframe\\n',dataframe_groupie)\n",
    "\n",
    "# lets groupby and aggregate \n",
    "# groupby - company and find the sum of their sales \n",
    "print('Groupby company and sum their sales')\n",
    "print(dataframe_groupie.groupby('Company').sum())\n",
    "\n",
    "print('Groupby company and max sales of the company')\n",
    "print(dataframe_groupie.groupby('Company').max())\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# groupby describe - keyword \n",
    "print('Describe groupby\\n',dataframe_groupie.groupby('Company').describe())\n",
    "print('--------------------------------------------------')\n",
    "print('Transposed Describe groupby\\n', dataframe_groupie.groupby('Company').describe().transpose())\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging , Joining and concatenating \n",
    "section6 - L32 \n",
    "> concatenation - pd.concat - glues the dataframes along cols and rows - axis \n",
    "> size of the dataframes should match \n",
    "\n",
    "> merge - pd.merge keyword - merge/join based on a common column \n",
    "> inner(precise match), outer(left and right checked - no match NaN) , left(left data checked with all right data), right merge (right data checked with all left data)\n",
    "\n",
    "> Join - based on the index rather than the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframes\n",
      "     A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3 \n",
      "     A   B   C   D\n",
      "4  A4  B4  C4  D4\n",
      "5  A5  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7 \n",
      "       A    B    C    D\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11 \n",
      "\n",
      "Concatenate rowise\n",
      "       A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "--------------------------------------------------\n",
      "Concatenate colwise\n",
      "       A    B    C    D    A    B    C    D    A    B    C    D\n",
      "0    A0   B0   C0   D0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "1    A1   B1   C1   D1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2    A2   B2   C2   D2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "3    A3   B3   C3   D3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4   NaN  NaN  NaN  NaN   A4   B4   C4   D4  NaN  NaN  NaN  NaN\n",
      "5   NaN  NaN  NaN  NaN   A5   B5   C5   D5  NaN  NaN  NaN  NaN\n",
      "6   NaN  NaN  NaN  NaN   A6   B6   C6   D6  NaN  NaN  NaN  NaN\n",
      "7   NaN  NaN  NaN  NaN   A7   B7   C7   D7  NaN  NaN  NaN  NaN\n",
      "8   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   A8   B8   C8   D8\n",
      "9   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   A9   B9   C9   D9\n",
      "10  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  A10  B10  C10  D10\n",
      "11  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  A11  B11  C11  D11\n",
      "--------------------------------------------------\n",
      "  key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3 \n",
      "   key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K3  C3  D3\n",
      "--------------------------------------------------\n",
      "Merge based on the common column key\n",
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "--------------------------------------------------\n",
      "  key1 key2   A   B\n",
      "0   K0   K0  A0  B0\n",
      "1   K0   K1  A1  B1\n",
      "2   K1   K0  A2  B2\n",
      "3   K2   K1  A3  B3 \n",
      "   key1 key2   C   D\n",
      "0   K0   K0  C0  D0\n",
      "1   K1   K0  C1  D1\n",
      "2   K1   K0  C2  D2\n",
      "3   K2   K0  C3  D3\n",
      "--------------------------------------------------\n",
      "Inner merge\n",
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n",
      "--------------------------------------------------\n",
      "Outer merge\n",
      "  key1 key2    A    B    C    D\n",
      "0   K0   K0   A0   B0   C0   D0\n",
      "1   K0   K1   A1   B1  NaN  NaN\n",
      "2   K1   K0   A2   B2   C1   D1\n",
      "3   K1   K0   A2   B2   C2   D2\n",
      "4   K2   K1   A3   B3  NaN  NaN\n",
      "5   K2   K0  NaN  NaN   C3   D3\n",
      "--------------------------------------------------\n",
      "Right merge\n",
      "  key1 key2    A    B   C   D\n",
      "0   K0   K0   A0   B0  C0  D0\n",
      "1   K1   K0   A2   B2  C1  D1\n",
      "2   K1   K0   A2   B2  C2  D2\n",
      "3   K2   K0  NaN  NaN  C3  D3\n",
      "--------------------------------------------------\n",
      "Left merge\n",
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "--------------------------------------------------\n",
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2 \n",
      "      C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "--------------------------------------------------\n",
      "Inner join\n",
      "      A   B   C   D\n",
      "K0  A0  B0  C0  D0\n",
      "K2  A2  B2  C2  D2\n",
      "--------------------------------------------------\n",
      "Outer join\n",
      "       A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n",
      "--------------------------------------------------\n",
      "Left join\n",
      "      A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n",
      "--------------------------------------------------\n",
      "Right join\n",
      "       A    B   C   D\n",
      "K0   A0   B0  C0  D0\n",
      "K2   A2   B2  C2  D2\n",
      "K3  NaN  NaN  C3  D3\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7]) \n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                        index=[8, 9, 10, 11])\n",
    "\n",
    "print('The dataframes\\n', df1,'\\n', df2,'\\n',df3,'\\n')\n",
    "\n",
    "print('Concatenate rowise\\n', pd.concat([df1,df2,df3]))\n",
    "print('--------------------------------------------------')\n",
    "print('Concatenate colwise\\n', pd.concat([df1,df2,df3], axis=1))\n",
    "# print('Fillna\\n', pd.concat([df1,df2,df3],axis=1).fillna(value='FNA'))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# merge \n",
    "\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "   \n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                          'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                          'D': ['D0', 'D1', 'D2', 'D3']})  \n",
    "\n",
    "print(left,'\\n',right)\n",
    "print('--------------------------------------------------')\n",
    "print('Merge based on the common column key')\n",
    "print(pd.merge(left, right, how='inner', on='key'))\n",
    "print('--------------------------------------------------')\n",
    "# complex merging \n",
    "\n",
    "left_m = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "    \n",
    "right_m = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                               'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                                  'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                                  'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "print(left_m,'\\n', right_m)\n",
    "print('--------------------------------------------------')\n",
    "print('Inner merge') # outputs conditions that matches exactly - no non matching records at all\n",
    "print(pd.merge(left_m,right_m,how='inner', on=['key1', 'key2'])) \n",
    "print('--------------------------------------------------')\n",
    "print('Outer merge') # outputs results that didnt match the condition also \n",
    "print(pd.merge(left_m,right_m,how='outer', on=['key1','key2'])) \n",
    "print('--------------------------------------------------')\n",
    "print('Right merge') # output results - preference to the right table -outputs records matching right table\n",
    "print(pd.merge(left_m, right_m, how='right', on=['key1', 'key2']))\n",
    "print('--------------------------------------------------')\n",
    "print('Left merge') # output results -preference to the left table-outputs records matching left table\n",
    "print(pd.merge(left_m,right_m,how='left', on=['key1','key2']))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "\n",
    "# JOIN \n",
    "left_j = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                      index=['K0', 'K1', 'K2']) \n",
    "\n",
    "right_j = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    "\n",
    "\n",
    "print(left_j,'\\n', right_j)\n",
    "print('--------------------------------------------------')\n",
    "print('Inner join\\n', left_j.join(right_j, how='inner'))  # only matching indexes will be in output \n",
    "print('--------------------------------------------------')\n",
    "print('Outer join\\n', left_j.join(right_j, how='outer'))# both matching and non matching records in output\n",
    "print('--------------------------------------------------')\n",
    "print('Left join\\n', left_j.join(right_j, how='left')) # check the left table records for matches \n",
    "# if not NaN for the left records - unmatched right records neglected \n",
    "print('--------------------------------------------------')\n",
    "print('Right join\\n', left_j.join(right_j, how='right')) # checks the right table records for matches in left \n",
    "# unmatched left table records neglected \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations \n",
    "section 6 - L33\n",
    "> Operations applied on columns \n",
    "> nunique > value_counts > boolean conditioning > & , | > .apply() > len , lambda\n",
    "> drop \n",
    "> .index > .columns \n",
    "> sort_values \n",
    "> .isnull()\n",
    "> .pivot_table()\n",
    "> .head - displays the first 5 rows \n",
    "> .corr() - correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n",
      "3     4   444  xyz\n",
      "--------------------------------------------------\n",
      "Unique values\n",
      " [444 555 666]\n",
      "No of unique values\n",
      " 3\n",
      "Value counts\n",
      " 444    2\n",
      "555    1\n",
      "666    1\n",
      "Name: col2, dtype: int64\n",
      "--------------------------------------------------\n",
      "   col1  col2 col3\n",
      "2     3   666  ghi\n",
      "3     4   444  xyz\n",
      "--------------------------------------------------\n",
      "   col1  col2 col3\n",
      "2     3   666  ghi\n",
      "--------------------------------------------------\n",
      "Apply on function\n",
      " 0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "Name: col1, dtype: int64\n",
      "--------------------------------------------------\n",
      "Apply on lambda\n",
      " 0    2\n",
      "1    4\n",
      "2    6\n",
      "3    8\n",
      "Name: col1, dtype: int64\n",
      "--------------------------------------------------\n",
      "Apply on inbuilt\n",
      " 0    3\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "Name: col3, dtype: int64\n",
      "--------------------------------------------------\n",
      "   col2 col3\n",
      "0   444  abc\n",
      "1   555  def\n",
      "2   666  ghi\n",
      "3   444  xyz\n",
      "--------------------------------------------------\n",
      "Index(['col1', 'col2', 'col3'], dtype='object')\n",
      "RangeIndex(start=0, stop=4, step=1)\n",
      "--------------------------------------------------\n",
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "3     4   444  xyz\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n",
      "--------------------------------------------------\n",
      "    col1   col2   col3\n",
      "0  False  False  False\n",
      "1  False  False  False\n",
      "2  False  False  False\n",
      "3  False  False  False\n",
      "--------------------------------------------------\n",
      "     A    B  C  D\n",
      "0  foo  one  x  1\n",
      "1  foo  one  y  3\n",
      "2  foo  two  x  2\n",
      "3  bar  two  y  5\n",
      "4  bar  one  x  4\n",
      "5  bar  one  y  1\n",
      "--------------------------------------------------\n",
      "Pivot table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C          x    y\n",
       "A   B            \n",
       "bar one  4.0  1.0\n",
       "    two  NaN  5.0\n",
       "foo one  1.0  3.0\n",
       "    two  2.0  NaN"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})\n",
    "print(df.head())   \n",
    "print('--------------------------------------------------')\n",
    "# finding unique vals \n",
    "\n",
    "print('Unique values\\n', df['col2'].unique())\n",
    "print('No of unique values\\n', df['col2'].nunique())\n",
    "print('Value counts\\n', df['col2'].value_counts())\n",
    "print('--------------------------------------------------')\n",
    "# conditional selection \n",
    "# df_bool = df['col1']>2\n",
    "\n",
    "print(df[df['col1']>2]) \n",
    "print('--------------------------------------------------')\n",
    "# & | operators \n",
    "\n",
    "df_bool = df['col1'] > 2 \n",
    "df[df_bool]\n",
    "\n",
    "print(df[(df['col1']>2) & (df['col2']>444)])\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# .apply keyword - for func and lambda \n",
    "# broadcasts basically \n",
    "\n",
    "def broadcast(x):\n",
    "    return x*2 \n",
    "\n",
    "print('Apply on function\\n',df['col1'].apply(broadcast))  # multiplies col1 with 2 \n",
    "print('--------------------------------------------------')\n",
    "print('Apply on lambda\\n',df['col1'].apply(lambda x: x*2)) # same as above\n",
    "print('--------------------------------------------------')\n",
    "print('Apply on inbuilt\\n',df['col3'].apply(len))   # 3 broadcasted for col3\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# drop keyword \n",
    "\n",
    "print(df.drop('col1', axis=1))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# .columns, .index \n",
    "\n",
    "print(df.columns)\n",
    "print(df.index)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# sort \n",
    "print(df.sort_values('col2'))\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# null values \n",
    "print(df.isnull())\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "# pivot table \n",
    "\n",
    "data = {'A':['foo','foo','foo','bar','bar','bar'],\n",
    "     'B':['one','one','two','two','one','one'],\n",
    "       'C':['x','y','x','y','x','y'],\n",
    "       'D':[1,3,2,5,4,1]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Pivot table')\n",
    "df.pivot_table(values='D', index=['A','B'], columns=['C'] )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input and output \n",
    "> Section 6 - L34 \n",
    "> data sources - csv, excel , html , sql \n",
    "> .read keyword \n",
    "> .to \n",
    "> .info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframed csv\n",
      "     a   b   c   d\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n",
      "The Sql table in memory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   a   b   c   d\n",
       "0      0   0   1   2   3\n",
       "1      1   4   5   6   7\n",
       "2      2   8   9  10  11\n",
       "3      3  12  13  14  15"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# reading data - csv \n",
    "\n",
    "df_csv = pd.read_csv('example')\n",
    "print('Dataframed csv\\n', df_csv )\n",
    "\n",
    "df_csv.to_csv('My_output', index=False)\n",
    "pd.read_csv('My_output')\n",
    "\n",
    "# reading data - excel \n",
    "\n",
    "df_xlsx = pd.read_excel('Excel_Sample.xlsx', sheet_name='Sheet1', index=False)\n",
    "df_xlsx\n",
    "\n",
    "df_xlsx.to_excel('Excel_Sample2.xlsx', sheet_name='NewSheet')\n",
    "pd.read_excel('Excel_Sample2.xlsx', index=False)\n",
    "\n",
    "# read html data\n",
    "\n",
    "df_html = pd.read_html('https://www.fdic.gov/bank/individual/failed/banklist.html')\n",
    "type(df_html) # list \n",
    "df_html[0]\n",
    "\n",
    "\n",
    "# read sql data \n",
    "from sqlalchemy import create_engine   # create a sql engine \n",
    "engine = create_engine('sqlite:///:memory:')  # engine flavour in the memory  - the connection basically \n",
    "\n",
    "# using the df_csv data to convert it into a sql table \n",
    "df_csv.to_sql('my_sqltable', engine)\n",
    "print('The Sql table in memory')\n",
    "pd.read_sql('my_sqltable', con=engine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
