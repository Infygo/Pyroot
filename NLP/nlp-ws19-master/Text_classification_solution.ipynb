{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Only to be executed when hosted on colab.research.google.com</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-d144f4156c75>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-d144f4156c75>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    https://github.com/Ystrehlow/nlp-ws19\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "!python -m spacy download de_core_news_sm\n",
    "import os\n",
    "\n",
    "!git clone https://github.com/YStrehlow/nlp-ws19.git\n",
    "\n",
    "os.chdir('nlp-ws19')\n",
    "https://github.com/Ystrehlow/nlp-ws19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>###################################################</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vravindran\\AppData\\Local\\Continuum\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from plot_cm import plot_confusion_matrix\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the .csv file into the variable \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>char_count</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>content_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337240</td>\n",
       "      <td>4894</td>\n",
       "      <td>'Wieder einmal will die Türkei Abgeordnete nic...</td>\n",
       "      <td>'Erneuter Incirlik-Eklat Pokern um den \"Tornad...</td>\n",
       "      <td>'http://www.spiegel.de//politik/deutschland/in...</td>\n",
       "      <td>politik</td>\n",
       "      <td>'Türkei Abgeordnete Incirlik lassen. Bundesreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337259</td>\n",
       "      <td>469</td>\n",
       "      <td>'Stuttgart (dpa/lsw) - Ministerpräsident Winfr...</td>\n",
       "      <td>'Kretschmann empfängt Adelsfamilien zum gemein...</td>\n",
       "      <td>'http://www.sueddeutsche.de/news/politik/regie...</td>\n",
       "      <td>politik</td>\n",
       "      <td>'Stuttgart (dpa/lsw) - Ministerpräsident Winfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337262</td>\n",
       "      <td>372</td>\n",
       "      <td>'Cottbus (dpa/bb) - Der Braunkohlenausschuss d...</td>\n",
       "      <td>'Braunkohlenausschuss kommt nach Revierkonzept...</td>\n",
       "      <td>'http://www.sueddeutsche.de/news/wirtschaft/en...</td>\n",
       "      <td>wirtschaft</td>\n",
       "      <td>'Cottbus (dpa/bb) - Braunkohlenausschuss Land ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337267</td>\n",
       "      <td>3404</td>\n",
       "      <td>'Frank Plasberg lässt die Erfolgsaussichten de...</td>\n",
       "      <td>'\"Hart aber fair\" mit Frank Plasberg Es muss n...</td>\n",
       "      <td>'http://www.sueddeutsche.de/medien/hart-aber-f...</td>\n",
       "      <td>medien</td>\n",
       "      <td>'Frank Plasberg lässt Erfolgsaussichten SPD-Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337271</td>\n",
       "      <td>492</td>\n",
       "      <td>'Washington (dpa) - US-Präsident Donald Trump ...</td>\n",
       "      <td>'McMaster: Bericht über Trumps Geheimnis-Weite...</td>\n",
       "      <td>'http://www.sueddeutsche.de/news/politik/gehei...</td>\n",
       "      <td>politik</td>\n",
       "      <td>'Washington (dpa) - US-Präsident Donald Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>337278</td>\n",
       "      <td>502</td>\n",
       "      <td>'New York (dpa) - UN-Generalsekretär António G...</td>\n",
       "      <td>'Vereinte Nationen verurteilen Nordkoreas Rake...</td>\n",
       "      <td>'http://www.sueddeutsche.de/news/politik/konfl...</td>\n",
       "      <td>politik</td>\n",
       "      <td>'New York (dpa) - UN-Generalsekretär António G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>337284</td>\n",
       "      <td>2638</td>\n",
       "      <td>'Düsseldorf – Die SPD will nach ihrer schweren...</td>\n",
       "      <td>'Nach NRW-Schlappe | SPD schließt große&amp;lt;br ...</td>\n",
       "      <td>'http://www.bild.de/politik/inland/politik/nrw...</td>\n",
       "      <td>politik</td>\n",
       "      <td>'Düsseldorf – SPD schwer Niederlage Landtagswa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>337294</td>\n",
       "      <td>2317</td>\n",
       "      <td>'Nordkorea könnte Experten zufolge hinter der ...</td>\n",
       "      <td>'Experten: Nordkorea könnte hinter weltweiter ...</td>\n",
       "      <td>'http://www.donaukurier.de/nachrichten/wirtsch...</td>\n",
       "      <td>wirtschaft</td>\n",
       "      <td>'Nordkorea Experte zufolge jung weltweit Cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>337297</td>\n",
       "      <td>153</td>\n",
       "      <td>'Der Bundesgerichtshof (BGH) hat der Unterlass...</td>\n",
       "      <td>'BGH-Urteil - Darlehenskontogebühren bei Bausp...</td>\n",
       "      <td>'http://www.donaukurier.de/nachrichten/wirtsch...</td>\n",
       "      <td>wirtschaft</td>\n",
       "      <td>'Bundesgerichtshof (BGH) Unterlassungsklage Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>337298</td>\n",
       "      <td>2317</td>\n",
       "      <td>'Nordkorea könnte Experten zufolge hinter der ...</td>\n",
       "      <td>'Experten: Nordkorea könnte hinter weltweiter ...</td>\n",
       "      <td>'http://www.donaukurier.de/nachrichten/medien/...</td>\n",
       "      <td>medien</td>\n",
       "      <td>'Nordkorea Experte zufolge jung weltweit Cyber...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  char_count                                            content  \\\n",
       "0  337240        4894  'Wieder einmal will die Türkei Abgeordnete nic...   \n",
       "1  337259         469  'Stuttgart (dpa/lsw) - Ministerpräsident Winfr...   \n",
       "2  337262         372  'Cottbus (dpa/bb) - Der Braunkohlenausschuss d...   \n",
       "3  337267        3404  'Frank Plasberg lässt die Erfolgsaussichten de...   \n",
       "4  337271         492  'Washington (dpa) - US-Präsident Donald Trump ...   \n",
       "5  337278         502  'New York (dpa) - UN-Generalsekretär António G...   \n",
       "6  337284        2638  'Düsseldorf – Die SPD will nach ihrer schweren...   \n",
       "7  337294        2317  'Nordkorea könnte Experten zufolge hinter der ...   \n",
       "8  337297         153  'Der Bundesgerichtshof (BGH) hat der Unterlass...   \n",
       "9  337298        2317  'Nordkorea könnte Experten zufolge hinter der ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  'Erneuter Incirlik-Eklat Pokern um den \"Tornad...   \n",
       "1  'Kretschmann empfängt Adelsfamilien zum gemein...   \n",
       "2  'Braunkohlenausschuss kommt nach Revierkonzept...   \n",
       "3  '\"Hart aber fair\" mit Frank Plasberg Es muss n...   \n",
       "4  'McMaster: Bericht über Trumps Geheimnis-Weite...   \n",
       "5  'Vereinte Nationen verurteilen Nordkoreas Rake...   \n",
       "6  'Nach NRW-Schlappe | SPD schließt große&lt;br ...   \n",
       "7  'Experten: Nordkorea könnte hinter weltweiter ...   \n",
       "8  'BGH-Urteil - Darlehenskontogebühren bei Bausp...   \n",
       "9  'Experten: Nordkorea könnte hinter weltweiter ...   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  'http://www.spiegel.de//politik/deutschland/in...     politik   \n",
       "1  'http://www.sueddeutsche.de/news/politik/regie...     politik   \n",
       "2  'http://www.sueddeutsche.de/news/wirtschaft/en...  wirtschaft   \n",
       "3  'http://www.sueddeutsche.de/medien/hart-aber-f...      medien   \n",
       "4  'http://www.sueddeutsche.de/news/politik/gehei...     politik   \n",
       "5  'http://www.sueddeutsche.de/news/politik/konfl...     politik   \n",
       "6  'http://www.bild.de/politik/inland/politik/nrw...     politik   \n",
       "7  'http://www.donaukurier.de/nachrichten/wirtsch...  wirtschaft   \n",
       "8  'http://www.donaukurier.de/nachrichten/wirtsch...  wirtschaft   \n",
       "9  'http://www.donaukurier.de/nachrichten/medien/...      medien   \n",
       "\n",
       "                                content_preprocessed  \n",
       "0  'Türkei Abgeordnete Incirlik lassen. Bundesreg...  \n",
       "1  'Stuttgart (dpa/lsw) - Ministerpräsident Winfr...  \n",
       "2  'Cottbus (dpa/bb) - Braunkohlenausschuss Land ...  \n",
       "3  'Frank Plasberg lässt Erfolgsaussichten SPD-Ka...  \n",
       "4  'Washington (dpa) - US-Präsident Donald Trump ...  \n",
       "5  'New York (dpa) - UN-Generalsekretär António G...  \n",
       "6  'Düsseldorf – SPD schwer Niederlage Landtagswa...  \n",
       "7  'Nordkorea Experte zufolge jung weltweit Cyber...  \n",
       "8  'Bundesgerichtshof (BGH) Unterlassungsklage Ve...  \n",
       "9  'Nordkorea Experte zufolge jung weltweit Cyber...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate how many instances of each class are present in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport         6366\n",
       "politik       5110\n",
       "wirtschaft    3341\n",
       "kultur        1366\n",
       "leben         1264\n",
       "medien        1103\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the german spacy word model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply spacy pre-processing to content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = nlp.pipe(data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the stopwords file \"stopwords.txt\" line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'r') as f:\n",
    "    stopwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove whitespaces and newlines from the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [x.strip() for x in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stop_word(sw):\n",
    "    if sw.startswith(\"#\") or sw.startswith(\"//\"):\n",
    "        return\n",
    "    nlp.vocab[sw].is_stop = True\n",
    "    sw = sw[0].upper() + sw[1:]\n",
    "    nlp.vocab[sw].is_stop = True\n",
    "    \n",
    "for w in stopwords:\n",
    "    set_stop_word(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line takes really long to execute. Stopwords are removed and lemmas are extracted.\n",
    "#the result from this line is already stored in data['content_preprocessed'] -> see next line\n",
    "\n",
    "#content_without_stopwords=[]\n",
    "#for t in content:\n",
    "#    content_without_stopwords.append(\"\".join(list(\"\".join(tok.lemma_ + tok.whitespace_) for tok in t if not tok.is_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_without_stopwords = data['content_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_without_stopwords[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into two sets: one for training the classifier and the other one for testing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int((len(data)/100)*80)\n",
    "\n",
    "train = data[:split]\n",
    "test = data[split:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the texts with the TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=1000, min_df=2)\n",
    "train_x = tfidf_vectorizer.fit_transform(train['content_preprocessed']).toarray()\n",
    "test_x = tfidf_vectorizer.transform(test['content_preprocessed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the labels with the LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train['category'])\n",
    "test_y = le.transform(test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(10, random_state=2)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "predictions = clf.predict(test_x)\n",
    "cnf_matrix = confusion_matrix(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(predictions, test_y))\n",
    "cf_matrix_plot = plot_confusion_matrix(cnf_matrix, classes=le.classes_, title='', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_texts = []\n",
    "for text in data['content_preprocessed'][:1000]:\n",
    "    lda_texts.append([tok.text for tok in nlp(text) if tok.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dictionary = Dictionary(lda_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in lda_texts]\n",
    "\n",
    "lda = LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda, common_corpus, dictionary=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_texts = []\n",
    "for i, text in enumerate(data['content_preprocessed']):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    if data['category'][i] == 'politik':\n",
    "        politic_texts.append([tok.text for tok in nlp(text) if tok.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_dictionary = Dictionary(politic_texts)\n",
    "politic_corpus = [politic_dictionary.doc2bow(text) for text in politic_texts]\n",
    "\n",
    "politic_lda = LdaModel(politic_corpus, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_vis = pyLDAvis.gensim.prepare(politic_lda, politic_corpus, dictionary=politic_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
