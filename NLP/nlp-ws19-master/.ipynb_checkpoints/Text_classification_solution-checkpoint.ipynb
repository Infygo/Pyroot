{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Only to be executed when hosted on colab.research.google.com</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.33.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: funcy in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.12)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.10)\n",
      "Requirement already satisfied: numexpr in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.6.9)\n",
      "Requirement already satisfied: future in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (40.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\vravindran\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vravindran\\AppData\\Local\\Continuum\\anaconda3\\python.exe: No module named spacy\n",
      "Cloning into 'nlp-ws19'...\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "!python -m spacy download de_core_news_sm\n",
    "import os\n",
    "\n",
    "!git clone https://github.com/YStrehlow/nlp-ws19.git\n",
    "\n",
    "os.chdir('nlp-ws19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>###################################################</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b80c56e2202>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from plot_cm import plot_confusion_matrix\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the .csv file into the variable \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate how many instances of each class are present in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the german spacy word model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1c95052c3bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"de_core_news_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply spacy pre-processing to content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = nlp.pipe(data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the stopwords file \"stopwords.txt\" line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt', 'r') as f:\n",
    "    stopwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove whitespaces and newlines from the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [x.strip() for x in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stop_word(sw):\n",
    "    if sw.startswith(\"#\") or sw.startswith(\"//\"):\n",
    "        return\n",
    "    nlp.vocab[sw].is_stop = True\n",
    "    sw = sw[0].upper() + sw[1:]\n",
    "    nlp.vocab[sw].is_stop = True\n",
    "    \n",
    "for w in stopwords:\n",
    "    set_stop_word(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line takes really long to execute. Stopwords are removed and lemmas are extracted.\n",
    "#the result from this line is already stored in data['content_preprocessed'] -> see next line\n",
    "\n",
    "#content_without_stopwords=[]\n",
    "#for t in content:\n",
    "#    content_without_stopwords.append(\"\".join(list(\"\".join(tok.lemma_ + tok.whitespace_) for tok in t if not tok.is_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_without_stopwords = data['content_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_without_stopwords[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into two sets: one for training the classifier and the other one for testing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int((len(data)/100)*80)\n",
    "\n",
    "train = data[:split]\n",
    "test = data[split:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the texts with the TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=1000, min_df=2)\n",
    "train_x = tfidf_vectorizer.fit_transform(train['content_preprocessed']).toarray()\n",
    "test_x = tfidf_vectorizer.transform(test['content_preprocessed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the labels with the LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(train['category'])\n",
    "test_y = le.transform(test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(10, random_state=2)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "predictions = clf.predict(test_x)\n",
    "cnf_matrix = confusion_matrix(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(predictions, test_y))\n",
    "cf_matrix_plot = plot_confusion_matrix(cnf_matrix, classes=le.classes_, title='', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_texts = []\n",
    "for text in data['content_preprocessed'][:1000]:\n",
    "    lda_texts.append([tok.text for tok in nlp(text) if tok.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dictionary = Dictionary(lda_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in lda_texts]\n",
    "\n",
    "lda = LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda, common_corpus, dictionary=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_texts = []\n",
    "for i, text in enumerate(data['content_preprocessed']):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    if data['category'][i] == 'politik':\n",
    "        politic_texts.append([tok.text for tok in nlp(text) if tok.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_dictionary = Dictionary(politic_texts)\n",
    "politic_corpus = [politic_dictionary.doc2bow(text) for text in politic_texts]\n",
    "\n",
    "politic_lda = LdaModel(politic_corpus, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_vis = pyLDAvis.gensim.prepare(politic_lda, politic_corpus, dictionary=politic_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
