Preprocessing 
----------------
Tokenisation  
Normalization - caps / small/ 1->one
stopwords - fillers 
stemming/ lemmatization - overstemming -> Universe , university - univers - snipping the word
Lemmatization - 
part of speech tagging 


Models 
-----------
Bag of words vector - No of occurences of word in a Phrase 
tf-idf 
Word embeddings 

